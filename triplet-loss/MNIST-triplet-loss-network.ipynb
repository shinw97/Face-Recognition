{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/KinWaiCheuk/Triplet-net-keras/blob/master/Triplet%20NN%20Test%20on%20MNIST.ipynb\n",
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '../dataset/mnist-triplet-loss/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "#     print('y_pred.shape = ',y_pred)\n",
    "    \n",
    "    total_length = y_pred.shape.as_list()[-1]\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_length*1/3)]\n",
    "    positive = y_pred[:,int(total_length*1/3):int(total_length*2/3)]\n",
    "    negative = y_pred[:,int(total_length*2/3):int(total_length*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss\n",
    "# def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "#     \"\"\"\n",
    "#     Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "#     Arguments:\n",
    "#     y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "#     y_pred -- python list containing three objects:\n",
    "#             anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "#             positive -- the encodings for the positive images, of shape (None, 128)\n",
    "#             negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "#     Returns:\n",
    "#     loss -- real number, value of the loss\n",
    "#     \"\"\"\n",
    "#     anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "#     # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "#     pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1) \n",
    "#     # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "#     neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "#     # Step 3: subtract the two previous distances and add alpha.\n",
    "#     basic_loss = pos_dist - neg_dist + alpha\n",
    "#     # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "#     loss = tf.reduce_sum(tf.maximum(basic_loss , 0.0))\n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_network(in_dims):\n",
    "    \"\"\"\n",
    "    Base network to be shared.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(5,(7,7),padding='same',input_shape=(in_dims[0],in_dims[1],in_dims[2],),activation='relu',name='conv1'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool1'))\n",
    "    model.add(Conv2D(7,(5,5),padding='same',activation='relu',name='conv2'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool2'))\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(4,name='embeddings'))\n",
    "    # model.add(Dense(600))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_triplet_dataset():\n",
    "    X_train = np.load(DATASET_DIR + 'tr_triplets.npy')\n",
    "    X_test = np.load(DATASET_DIR + 'ts_triplets.npy')\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = load_triplet_dataset()\n",
    "input_shape = X_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y_train = np.empty((X_train.shape[0], 1))\n",
    "dummy_y_test = np.empty((X_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_input = Input((28,28,1, ), name='anchor_input')\n",
    "positive_input = Input((28,28,1, ), name='positive_input')\n",
    "negative_input = Input((28,28,1, ), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "shared_network = base_network([28,28,1,])\n",
    "\n",
    "\n",
    "encoded_anchor = shared_network(anchor_input)\n",
    "encoded_positive = shared_network(positive_input)\n",
    "encoded_negative = shared_network(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4)            2508        anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 12)           0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,508\n",
      "Trainable params: 2,508\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=triplet_loss, optimizer=adam)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54200 samples, validate on 8910 samples\n",
      "Epoch 1/10\n",
      "54200/54200 [==============================] - 10s 187us/step - loss: 0.0720 - val_loss: 0.0598\n",
      "Epoch 2/10\n",
      "54200/54200 [==============================] - 9s 172us/step - loss: 0.0633 - val_loss: 0.0517\n",
      "Epoch 3/10\n",
      "54200/54200 [==============================] - 9s 170us/step - loss: 0.0556 - val_loss: 0.0452\n",
      "Epoch 4/10\n",
      "54200/54200 [==============================] - 10s 191us/step - loss: 0.0498 - val_loss: 0.0404\n",
      "Epoch 5/10\n",
      "54200/54200 [==============================] - 10s 184us/step - loss: 0.0454 - val_loss: 0.0370\n",
      "Epoch 6/10\n",
      "54200/54200 [==============================] - 10s 180us/step - loss: 0.0420 - val_loss: 0.0343\n",
      "Epoch 7/10\n",
      "54200/54200 [==============================] - 10s 194us/step - loss: 0.0392 - val_loss: 0.0323\n",
      "Epoch 8/10\n",
      "54200/54200 [==============================] - 10s 192us/step - loss: 0.0370 - val_loss: 0.0308\n",
      "Epoch 9/10\n",
      "54200/54200 [==============================] - 10s 184us/step - loss: 0.0351 - val_loss: 0.0291\n",
      "Epoch 10/10\n",
      "54200/54200 [==============================] - 10s 189us/step - loss: 0.0334 - val_loss: 0.0280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2438a5048>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train[:, 0] ,X_train[:, 1],X_train[:, 2]],\n",
    "          y=dummy_y_train, \n",
    "          validation_data=([X_test[:, 0], X_test[:, 1], X_test[:, 2]], dummy_y_test), \n",
    "          epochs=10, \n",
    "          batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained-weights-model/MNIST-triplet-loss-network.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
